import tensorflow as tffrom tensorflow.examples.tutorials.mnist import input_dataimport numpy as npimport matplotlibmatplotlib.use('TkAgg')from matplotlib import pyplot as pltfrom skimage.io import imsaveimport osimport shutilimport my_mnist as mmyos.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'batch_size = 256max_epoch = 300h1_size = 150h2_size = 300z_size = 100img_height = 28img_width = 28img_size = img_height * img_widthto_train = 0to_restore = Falseoutput_path = "output"class GAN(object):    def __init__(self):                self.mnist = input_data.read_data_sets('MNIST_data', one_hot=True)        self.z = tf.placeholder(tf.float32, [batch_size, z_size], name="z_prior")        self.x = tf.placeholder(tf.float32, [batch_size, img_size], name="x_data")                self.keep_prob = tf.placeholder(tf.float32, name="keep_prob")                self.global_step = tf.Variable(0, name="global_step", trainable=False)        # define the network               self.x_generated, self.g_params = self.netG(self.z)            self.y_data, self.y_generated, self.d_params = self.netD(self.x,self.x_generated,self.keep_prob)            # define losses        self.d_loss = - (tf.log(self.y_data) + tf.log(1 - self.y_generated))        self.g_loss = - tf.log(self.y_generated)                t_vars = tf.trainable_variables()        self.d_vars = [var for var in t_vars if 'd_' in var.name]        self.g_vars = [var for var in t_vars if 'g_' in var.name]    def netG(self, z_prior):        with tf.variable_scope("generator") as scope:                        w1 = tf.Variable(tf.truncated_normal([z_size, h1_size], stddev=0.1), name="g_w1", dtype=tf.float32)            b1 = tf.Variable(tf.zeros([h1_size]), name="g_b1", dtype=tf.float32)            h1 = tf.nn.relu(tf.matmul(z_prior, w1) + b1)            w2 = tf.Variable(tf.truncated_normal([h1_size, h2_size], stddev=0.1), name="g_w2", dtype=tf.float32)            b2 = tf.Variable(tf.zeros([h2_size]), name="g_b2", dtype=tf.float32)            h2 = tf.nn.relu(tf.matmul(h1, w2) + b2)            w3 = tf.Variable(tf.truncated_normal([h2_size, img_size], stddev=0.1), name="g_w3", dtype=tf.float32)            b3 = tf.Variable(tf.zeros([img_size]), name="g_b3", dtype=tf.float32)            h3 = tf.matmul(h2, w3) + b3            x_generate = tf.nn.tanh(h3,name = "x_generate")            g_params = [w1, b1, w2, b2, w3, b3]            return x_generate, g_params    def netD(self, x_data, x_generated, keep_prob):        with tf.variable_scope("discriminator") as scope:            x_in = tf.concat([x_data, x_generated],0)            w1 = tf.Variable(tf.truncated_normal([img_size, h2_size], stddev=0.1), name="d_w1", dtype=tf.float32)            b1 = tf.Variable(tf.zeros([h2_size]), name="d_b1", dtype=tf.float32)            h1 = tf.nn.dropout(tf.nn.relu(tf.matmul(x_in, w1) + b1), rate =1-keep_prob)            w2 = tf.Variable(tf.truncated_normal([h2_size, h1_size], stddev=0.1), name="d_w2", dtype=tf.float32)            b2 = tf.Variable(tf.zeros([h1_size]), name="d_b2", dtype=tf.float32)            h2 = tf.nn.dropout(tf.nn.relu(tf.matmul(h1, w2) + b2), rate = 1 - keep_prob)            w3 = tf.Variable(tf.truncated_normal([h1_size, 1], stddev=0.1), name="d_w3", dtype=tf.float32)            b3 = tf.Variable(tf.zeros([1]), name="d_b3", dtype=tf.float32)            h3 = tf.matmul(h2, w3) + b3            y_data = tf.nn.sigmoid(tf.slice(h3, [0, 0], [batch_size, -1], name=None))            y_generated = tf.nn.sigmoid(tf.slice(h3, [batch_size, 0], [-1, -1], name=None))            d_params = [w1, b1, w2, b2, w3, b3]            return y_data, y_generated, d_paramsdef show_result(batch_res, fname, grid_size=(8, 8), grid_pad=5):    batch_res = 0.5 * batch_res.reshape((batch_res.shape[0], img_height, img_width))+0.5    #print(batch_res.shape[0]," ",batch_res.shape[1]," ",batch_res.shape[2] )    #print(average_picture.shape[0]," ",average_picture.shape[1]," ",average_picture.shape[2] )    img_h, img_w = batch_res.shape[1], batch_res.shape[2]    grid_h = img_h * grid_size[0] + grid_pad * (grid_size[0] - 1)    grid_w = img_w * grid_size[1] + grid_pad * (grid_size[1] - 1)    img_grid = np.zeros((grid_h, grid_w), dtype=np.uint8)    for i, res in enumerate(batch_res):        if i >= grid_size[0] * grid_size[1]:            break        img = (res) * 255        img = img.astype(np.uint8)        row = (i // grid_size[0]) * (img_h + grid_pad)        col = (i % grid_size[1]) * (img_w + grid_pad)        img_grid[row:row + img_h, col:col + img_w] = img    imsave(fname, img_grid)def train():    gan = GAN()    optimizer = tf.train.AdamOptimizer(0.0001)    d_trainer = optimizer.minimize(gan.d_loss, var_list=gan.d_params)    g_trainer = optimizer.minimize(gan.g_loss, var_list=gan.g_params)    init = tf.global_variables_initializer()    saver = tf.train.Saver()    sess = tf.Session()    sess.run(init)    if to_restore:        saver.save(sess, output_path)    else:        if os.path.exists(output_path):            shutil.rmtree(output_path)        os.mkdir(output_path)        z_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)        steps = 60000 / batch_size        for i in range(sess.run(gan.global_step), max_epoch):            for j in np.arange(steps):                print("epoch:%s, iter:%s" % (i, j))                x_value, _ = gan.mnist.train.next_batch(batch_size)                x_value = 2 * x_value.astype(np.float32) - 1                z_value = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)                sess.run(d_trainer,feed_dict={gan.x: x_value, gan.z: z_value, gan.keep_prob: np.sum(0.7).astype(np.float32)})                if j % 1 == 0:                    sess.run(g_trainer,feed_dict={gan.x: x_value, gan.z: z_value, gan.keep_prob: np.sum(0.7).astype(np.float32)})            x_gen_val = sess.run(gan.x_generated, feed_dict={gan.z: z_sample_val})            show_result(x_gen_val, "output/sample{0}.jpg".format(i))            z_random_sample_val = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)            x_gen_val = sess.run(gan.x_generated, feed_dict={gan.z: z_random_sample_val})            show_result(x_gen_val, "output/random_sample{0}.jpg".format(i))            sess.run(tf.assign(gan.global_step, i + 1))            saver.save(sess, os.path.join(output_path, "model"),gan.global_step)            tf.reset_default_graph()def test():            saver = tf.train.import_meta_graph('output/model-216.meta')        gragh = tf.get_default_graph()        tensor_name_list = [tensor.name for tensor in gragh.as_graph_def().node]        #print(tensor_name_list)        z_prior = gragh.get_tensor_by_name("z_prior:0")        x_generated = gragh.get_tensor_by_name("generator/x_generate:0")    with tf.Session() as sess:            saver.restore(sess, tf.train.latest_checkpoint("output/"))        #sess.run(init)        #saver.restore(sess, chkpt_fname)            z_test_value = np.random.normal(0, 1, size=(batch_size, z_size)).astype(np.float32)        x_gen_val = sess.run(x_generated, feed_dict={z_prior: z_test_value})        np.savetxt("Data.txt",x_gen_val)        show_result(x_gen_val, "output/test_result.jpg")        #judge which picture will be the nearest picture to the test case        #In reality, we just assume we have the label, so this step can be ignored in practiceif __name__ == '__main__':    if to_train:        train()    else:        test()        print("end")